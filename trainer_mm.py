"""
å¤šæ¨¡æ€è”åˆè®­ç»ƒå™¨
é€‚é… MMRQVAEï¼ˆä¸€ä¸ªæ¨¡å‹åŒ…å«æ–‡æœ¬å’Œå›¾åƒä¸¤ä¸ª RQï¼‰
"""

import logging
import numpy as np
import torch
from time import time
from torch import optim
from tqdm import tqdm
from collections import defaultdict
from utils import ensure_dir, set_color
import os
from diagnose_lora import LoRADiagnostics
from check_alignment_gain import check_alignment_from_paired_loader


class MMTrainer(object):
    """å¤šæ¨¡æ€è®­ç»ƒå™¨ - é€‚é… MMRQVAE"""

    def __init__(self, args, model):
        self.args = args
        self.model = model
        self.logger = logging.getLogger()

        self.lr = args.lr
        self.learner = args.learner
        self.weight_decay = args.weight_decay
        self.epochs = args.epochs
        self.eval_step = min(args.eval_step, self.epochs)
        self.device = torch.device(args.device)
        self.ckpt_dir = args.ckpt_dir
        ensure_dir(self.ckpt_dir)

        self.best_loss = np.inf
        self.best_collision_text = np.inf
        self.best_collision_image = np.inf

        self.optimizer = self._build_optimizer()
        self.model = self.model.to(self.device)
        
        # å¯¹é½æ£€æŸ¥å‚æ•°ï¼ˆå¦‚æœ args ä¸­æ²¡æœ‰è¿™äº›å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼‰
        self.check_alignment = getattr(args, 'check_alignment', True)
        self.alignment_check_step = getattr(args, 'alignment_check_step', 10)  # æ¯ 10 ä¸ª epoch æ£€æŸ¥ä¸€æ¬¡
        
        # LoRA è¯Šæ–­å·¥å…·ï¼ˆæš‚æ—¶å…³é—­ï¼‰
        # self.diagnostics = LoRADiagnostics(
        #     model=self.model,
        #     output_dir=os.path.join(self.ckpt_dir, "diagnostics")
        # )

    def _build_optimizer(self):
        """æ„å»ºä¼˜åŒ–å™¨"""
        params = self.model.parameters()
        
        if self.learner.lower() == 'adamw':
            return optim.AdamW(params, lr=self.lr, weight_decay=self.weight_decay)
        elif self.learner.lower() == 'adam':
            return optim.Adam(params, lr=self.lr, weight_decay=self.weight_decay)
        else:
            return optim.Adam(params, lr=self.lr)

    def _check_nan(self, loss):
        if torch.isnan(loss):
            raise ValueError("Training loss is nan")

    def _train_epoch(self, train_data, epoch_idx):
        """è®­ç»ƒä¸€ä¸ª epoch"""
        self.model.train()

        total_loss = 0
        total_recon_loss = 0
        total_quant_loss = 0
        total_align_loss = 0

        pbar = tqdm(train_data, total=len(train_data), ncols=100,
                   desc=set_color(f"Train {epoch_idx}", "pink"))

        for batch_idx, (batch_text, batch_image, _) in enumerate(pbar):
            batch_text = batch_text.to(self.device)
            batch_image = batch_image.to(self.device)

            self.optimizer.zero_grad()

            # å‰å‘ä¼ æ’­ï¼ˆç¡¬é‡åŒ–ï¼‰
            (text_out, image_out, 
             text_rq_loss, image_rq_loss,
             text_indices, image_indices,
             z_q_text, z_q_image) = self.model(batch_text, batch_image)

            # è®¡ç®—æŸå¤±
            loss, loss_recon, loss_quant, align_loss = self.model.compute_loss(
                text_out, image_out,
                text_rq_loss, image_rq_loss,
                z_q_text, z_q_image,
                batch_text, batch_image
            )

            self._check_nan(loss)
            loss.backward()
            # å»ºè®®æ¯ 50 æˆ– 100 ä¸ª step æ‰“å°ä¸€æ¬¡ï¼Œåˆšå¼€å§‹è®­ç»ƒæ—¶å¯ä»¥è®¾ä¸º 10
            if batch_idx % 50 == 0: 
                print(f"\n--- [Raw LoRA Check] Step {epoch_idx}-{batch_idx} ---")
                
                # æ£€æŸ¥ Text æ¨¡æ€çš„ä½¿ç”¨ LoRA çš„å±‚
                if hasattr(self.model, 'text_rq'):
                    # è·å–å®é™…ä½¿ç”¨ LoRA çš„å±‚ç´¢å¼•
                    lora_layer_indices = []
                    if hasattr(self.args, 'lora_layers') and self.args.lora_layers:
                        try:
                            lora_layer_indices = [int(x.strip()) for x in self.args.lora_layers.split(',')]
                        except:
                            lora_layer_indices = []
                    
                    # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œå°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªä½¿ç”¨ LoRA çš„å±‚
                    if not lora_layer_indices:
                        for i, vq in enumerate(self.model.text_rq.vq_layers):
                            if hasattr(vq, 'use_lora') and vq.use_lora:
                                lora_layer_indices = [i]
                                break
                    
                    # æ£€æŸ¥ç¬¬ä¸€ä¸ªä½¿ç”¨ LoRA çš„å±‚
                    if lora_layer_indices:
                        layer_idx = lora_layer_indices[0]
                        if layer_idx < len(self.model.text_rq.vq_layers):
                            vq = self.model.text_rq.vq_layers[layer_idx]

                            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨LoRAä¸”å…·æœ‰å¿…è¦çš„å±æ€§ï¼ˆåªåœ¨ä½¿ç”¨LoRAçš„å±‚å­˜åœ¨ï¼‰
                            if (vq.use_lora and 
                                hasattr(vq, 'lora_A') and vq.lora_A is not None):

                                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ Recursive LoRA
                                use_recursive = getattr(self.model.text_rq, 'use_recursive_lora', False)

                                with torch.no_grad():
                                    # 1. ã€é‡çº§å¯¹æ¯”ã€‘
                                    # Base ç æœ¬çš„å¹³å‡å¼ºåº¦ (é€šå¸¸åœ¨ 0.1 ~ 1.0 ä¹‹é—´)
                                    base_norm = vq.embedding.weight.norm(dim=1).mean().item()

                                    # è·å–å½“å‰çš„ B çŸ©é˜µï¼ˆæ”¯æŒ Recursive LoRAï¼‰
                                    lora_B = vq.get_lora_B()
                                    if lora_B is not None:
                                        # LoRA åç½®çš„åŸå§‹å¼ºåº¦ (A @ B)
                                        lora_bias = torch.matmul(vq.lora_A, lora_B)
                                        lora_norm = lora_bias.norm(dim=1).mean().item()

                                        # è®¡ç®—å æ¯” (LoRA åˆ°åº•æ˜¯ä¸»åŠ›è¿˜æ˜¯å™ªéŸ³ï¼Ÿ)
                                        ratio = (lora_norm / (base_norm + 1e-6)) * 100

                                        # 2. ã€æ¢¯åº¦å¿ƒè·³ã€‘
                                        grad_A = 0.0
                                        if vq.lora_A.grad is not None:
                                            grad_A = vq.lora_A.grad.norm().item()

                                        if use_recursive:
                                            # Recursive LoRA: æ£€æŸ¥ B_init å’Œ evolution_network çš„æ¢¯åº¦
                                            grad_B_init = 0.0
                                            if hasattr(self.model.text_rq, 'B_init') and self.model.text_rq.B_init.grad is not None:
                                                grad_B_init = self.model.text_rq.B_init.grad.norm().item()

                                            grad_evol = 0.0
                                            if hasattr(self.model.text_rq, 'evolution_network'):
                                                for param in self.model.text_rq.evolution_network.parameters():
                                                    if param.grad is not None:
                                                        grad_evol += param.grad.norm().item()

                                            grad_B = grad_B_init + grad_evol

                                            # 3. ã€æ‰“å°æŠ¥å‘Šã€‘
                                            print(set_color(f"1. [å¼ºåº¦] Base: {base_norm:.6f} | LoRA: {lora_norm:.8f}", "cyan"))
                                            print(set_color(f"   => LoRA è´¡çŒ®å æ¯”: {ratio:.6f}%", "yellow"))
                                            print(set_color(f"2. [æ¢¯åº¦] Grad_A: {grad_A:.8f} | Grad_B_init: {grad_B_init:.8f} | Grad_evol: {grad_evol:.8f}", "cyan"))
                                        else:
                                            # æ ‡å‡† LoRA: æ£€æŸ¥ lora_B çš„æ¢¯åº¦
                                            grad_B = 0.0
                                            if hasattr(vq, 'lora_B') and vq.lora_B is not None and vq.lora_B.grad is not None:
                                                grad_B = vq.lora_B.grad.norm().item()

                                            # 3. ã€æ‰“å°æŠ¥å‘Šã€‘
                                            print(set_color(f"1. [å¼ºåº¦] Base: {base_norm:.6f} | LoRA: {lora_norm:.8f}", "cyan"))
                                            print(set_color(f"   => LoRA è´¡çŒ®å æ¯”: {ratio:.6f}%", "yellow"))
                                            print(set_color(f"2. [æ¢¯åº¦] Grad_A: {grad_A:.8f} | Grad_B: {grad_B:.8f}", "cyan"))

                                        # 4. ã€è‡ªåŠ¨åˆ¤åˆ«ã€‘
                                        if ratio < 0.1:
                                            print(set_color("   [è¯Šæ–­] ğŸ”´ èš‚èšæ’¼æ ‘ï¼šLoRA æ•°å€¼å¤ªå°ï¼Œè¢« Base æ·¹æ²¡äº†ï¼(å»ºè®®ï¼šå¤§å¹…å¢å¤§ A çš„åˆå§‹åŒ–)", "red"))
                                        elif ratio > 20.0:
                                            print(set_color("   [è¯Šæ–­] ğŸ”´ å–§å®¾å¤ºä¸»ï¼šLoRA æ•°å€¼å¤ªå¤§ï¼Œå¯èƒ½åœ¨ç ´åç‰¹å¾ï¼(å»ºè®®ï¼šå‡å°å­¦ä¹ ç‡)", "red"))
                                        elif grad_B == 0:
                                            print(set_color("   [è¯Šæ–­] ğŸ’€ æ¢¯åº¦æ–­è”ï¼šB æ²¡æœ‰æ”¶åˆ°æ¢¯åº¦ï¼Œæ£€æŸ¥ä»£ç é€»è¾‘ã€‚", "red"))
                                        else:
                                            print(set_color("   [è¯Šæ–­] ğŸŸ¢ çŠ¶æ€å¥åº·ï¼šæ•°å€¼åœ¨ä¸€ä¸ªåˆç†çš„è¾…åŠ©èŒƒå›´å†…ã€‚", "green"))
                                    else:
                                        print(set_color(f"   [è­¦å‘Š] Layer {layer_idx} çš„ B çŸ©é˜µä¸º None", "yellow"))
                            else:
                                print(set_color(f"   [è­¦å‘Š] Layer {layer_idx} æ²¡æœ‰ LoRA å‚æ•°", "yellow"))
                        else:
                            print(set_color(f"   [è­¦å‘Š] Layer {layer_idx} è¶…å‡ºèŒƒå›´", "yellow"))
                    else:
                        print(set_color("   [è­¦å‘Š] æ²¡æœ‰æ‰¾åˆ°ä½¿ç”¨ LoRA çš„å±‚", "yellow"))
            # ==========================================================
            self.optimizer.step()

            total_loss += loss.item()
            total_recon_loss += loss_recon.item()
            total_quant_loss += loss_quant.item()
            total_align_loss += align_loss.item()

        return total_loss, total_recon_loss, total_quant_loss, total_align_loss

    @torch.no_grad()
    def _valid_epoch(self, valid_data):
        """è¯„ä¼°"""
        self.model.eval()

        indices_list_text = []
        indices_list_image = []
        num_sample = 0

        for batch_text, batch_image, _ in tqdm(valid_data, desc=set_color("Eval", "pink"), leave=False):
            num_sample += len(batch_text)
            batch_text = batch_text.to(self.device)
            batch_image = batch_image.to(self.device)

            text_indices, image_indices = self.model.get_indices(text_x=batch_text, image_x=batch_image)

            indices = text_indices.view(-1, text_indices.shape[-1]).cpu().numpy()
            for index in indices:
                indices_list_text.append("-".join([str(int(_)) for _ in index]))

            indices = image_indices.view(-1, image_indices.shape[-1]).cpu().numpy()
            for index in indices:
                indices_list_image.append("-".join([str(int(_)) for _ in index]))

        collision_text = (num_sample - len(set(indices_list_text))) / num_sample
        collision_image = (num_sample - len(set(indices_list_image))) / num_sample

        return collision_text, collision_image

    def _save_checkpoint(self, epoch, name):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        state = {
            "args": self.args,
            "epoch": epoch,
            "state_dict": self.model.state_dict(),
            "optimizer": self.optimizer.state_dict(),
        }
        ckpt_path = os.path.join(self.ckpt_dir, f'{name}_model.pth')
        torch.save(state, ckpt_path, pickle_protocol=4)
        self.logger.info(set_color("Saving current", "blue") + f": {ckpt_path}")

    def fit(self, train_data):
        """è®­ç»ƒ"""
        self.logger.info("="*60)
        self.logger.info("MM-RQVAE Training: Single paired DataLoader (text,image,index)")
        self.logger.info("="*60)

        for epoch_idx in range(self.epochs):
            training_start_time = time()
            total_loss, recon_loss, quant_loss, align_loss = self._train_epoch(
                train_data, epoch_idx
            )
            training_end_time = time()

            print(f'epoch {epoch_idx}, total: {total_loss:.4f}, recon: {recon_loss:.4f}, '
                  f'quant: {quant_loss:.4f}, align: {align_loss:.4f}')
            # æ‰“å° Gate çš„å€¼
            """
            if hasattr(self.model, 'text_rq'):
                # è·å–æ–‡æœ¬æ¨¡æ€æ¯ä¸€å±‚çš„ gate
                text_gates = [
                    round(vq.gate.item(), 4) 
                    for vq in self.model.text_rq.vq_layers 
                    if hasattr(vq, 'gate')
                ]
                # è·å–å›¾åƒæ¨¡æ€æ¯ä¸€å±‚çš„ gate
                image_gates = [
                    round(vq.gate.item(), 4) 
                    for vq in self.model.image_rq.vq_layers 
                    if hasattr(vq, 'gate')
                ]
                self.logger.info(f"Text Gates: {text_gates}")
                self.logger.info(f"Image Gates: {image_gates}")
            """
            train_output = (
                set_color("epoch %d training", "green") + " [" +
                set_color("time", "blue") + ": %.2fs, " +
                set_color("total", "blue") + ": %.4f, " +
                set_color("recon", "blue") + ": %.4f, " +
                set_color("align", "blue") + ": %.4f]"
            ) % (epoch_idx, training_end_time - training_start_time, 
                 total_loss, recon_loss, align_loss)
            self.logger.info(train_output)

            # æ›´æ–° best_loss
            if total_loss < self.best_loss:
                self.best_loss = total_loss

            # è¯„ä¼°
            if (epoch_idx + 1) % self.eval_step == 0:
                collision_text, collision_image = self._valid_epoch(train_data)
                
                print(f'collision_text: {collision_text:.6f}, collision_image: {collision_image:.6f}')

                eval_output = (
                    set_color("epoch %d evaluating", "green") + " [" +
                    set_color("collision_text", "blue") + ": %.6f, " +
                    set_color("collision_image", "blue") + ": %.6f]"
                ) % (epoch_idx, collision_text, collision_image)
                self.logger.info(eval_output)

                # å¯¹é½å¢ç›Šæ£€æŸ¥ï¼ˆå¦‚æœå¯ç”¨ä¸”åœ¨æ£€æŸ¥å‘¨æœŸï¼‰
                if self.check_alignment and (epoch_idx + 1) % self.alignment_check_step == 0:
                    try:
                        self.logger.info(set_color("="*60, "yellow"))
                        self.logger.info(set_color(f"Checking alignment gain at epoch {epoch_idx}", "yellow"))
                        self.logger.info(set_color("="*60, "yellow"))
                        alignment_results = check_alignment_from_paired_loader(
                            self.model, train_data, self.device
                        )
                        # è®°å½•ç»“æœåˆ°æ—¥å¿—
                        self.logger.info(
                            f"Alignment Check Results: "
                            f"Base={alignment_results['sim_base']:.6f}, "
                            f"LoRA={alignment_results['sim_lora']:.6f}, "
                            f"Gain={alignment_results['gain']:.6f} "
                            f"({alignment_results['gain_percent']:.2f}%)"
                        )
                        self.logger.info(set_color("="*60, "yellow"))
                    except Exception as e:
                        self.logger.warning(f"Alignment check failed: {e}")

                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if collision_text < self.best_collision_text:
                    self.best_collision_text = collision_text
                    self._save_checkpoint(epoch_idx, 'best_text')

                if collision_image < self.best_collision_image:
                    self.best_collision_image = collision_image
                    self._save_checkpoint(epoch_idx, 'best_image')
                
                # LoRA è¯Šæ–­ï¼ˆæš‚æ—¶å…³é—­ï¼‰
                # metrics = self.diagnostics.collect_metrics(epoch_idx)
                # self.diagnostics.log_metrics(epoch_idx, metrics)

        return self.best_loss, self.best_collision_text, self.best_collision_image
